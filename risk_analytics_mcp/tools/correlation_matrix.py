"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç compute_correlation_matrix –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –º–∞—Ç—Ä–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.

–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–ø–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
"""

import asyncio
import time
from typing import List, Optional, Sequence

from fastmcp import Context
from opentelemetry import trace
from pydantic import Field

from moex_iss_sdk import IssClient
from moex_iss_sdk.error_mapper import ErrorMapper, ToolErrorModel
from moex_iss_sdk.exceptions import TooManyTickersError
from moex_iss_sdk.utils import validate_date_range

from ..calculations import build_returns_by_ticker
from ..calculations.correlation import InsufficientDataError, compute_correlation_matrix as calc_correlation_matrix
from ..mcp_instance import mcp
from ..models import CorrelationMatrixInput, CorrelationMatrixOutput
from ..tools.utils import ToolResult
from ..telemetry import NullTracing

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞)
_iss_client = None
_metrics = None
_tracing = NullTracing()
_max_tickers = None
_max_lookback_days = None
_NOOP_SPAN = type("NoopSpan", (), {"set_attribute": lambda self, *args, **kwargs: None})()


def init_tool_dependencies(iss_client, metrics, tracing, max_tickers, max_lookback_days):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."""
    global _iss_client, _metrics, _tracing, _max_tickers, _max_lookback_days
    _iss_client = iss_client
    _metrics = metrics
    _tracing = tracing or NullTracing()
    _max_tickers = max_tickers
    _max_lookback_days = max_lookback_days


tracer = trace.get_tracer(__name__)


def _map_error(exc: Exception) -> ToolErrorModel:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ ToolErrorModel."""
    if isinstance(exc, InsufficientDataError):
        return ToolErrorModel(
            error_type=getattr(exc, "error_type", "INSUFFICIENT_DATA"),
            message=str(exc) or "Insufficient data for correlation",
            details={"exception_type": type(exc).__name__},
        )
    return ErrorMapper.map_exception(exc)


def _fetch_ohlcv_for_tickers(
    iss_client: IssClient,
    tickers: Sequence[str],
    *,
    from_date,
    to_date,
    max_lookback_days: int,
):
    data: Dict[str, Sequence] = {}
    for ticker in tickers:
        data[ticker] = iss_client.get_ohlcv_series(
            ticker=ticker,
            board=iss_client.settings.default_board,
            from_date=from_date,
            to_date=to_date,
            interval="1d",
            max_lookback_days=max_lookback_days,
        )
    return data


def _map_error(exc: Exception) -> ToolErrorModel:
    if isinstance(exc, InsufficientDataError):
        return ToolErrorModel(
            error_type=getattr(exc, "error_type", "INSUFFICIENT_DATA"),
            message=str(exc) or "Insufficient data for correlation",
            details={"exception_type": type(exc).__name__},
        )
    return ErrorMapper.map_exception(exc)


def compute_correlation_matrix_core(
    payload,
    iss_client: IssClient,
    *,
    max_tickers: int,
    max_lookback_days: int,
) -> CorrelationMatrixOutput:
    input_model = payload if isinstance(payload, CorrelationMatrixInput) else CorrelationMatrixInput.model_validate(payload)

    if len(input_model.tickers) > max_tickers:
        raise TooManyTickersError(
            f"Too many tickers: {len(input_model.tickers)} > {max_tickers}",
            details={"tickers": input_model.tickers},
        )
    validate_date_range(input_model.from_date, input_model.to_date, max_lookback_days=max_lookback_days)

    ohlcv_by_ticker = _fetch_ohlcv_for_tickers(
        iss_client,
        input_model.tickers,
        from_date=input_model.from_date,
        to_date=input_model.to_date,
        max_lookback_days=max_lookback_days,
    )
    returns_by_ticker = build_returns_by_ticker(ohlcv_by_ticker)
    matrix, calc_metadata = compute_correlation_matrix(input_model.tickers, returns_by_ticker)

    metadata = {
        "from_date": input_model.from_date.isoformat(),
        "to_date": input_model.to_date.isoformat(),
        "tickers": input_model.tickers,
        "method": calc_metadata.get("method"),
        "num_observations": calc_metadata.get("num_observations"),
        "iss_base_url": iss_client.settings.base_url,
    }

    return CorrelationMatrixOutput.success(metadata=metadata, tickers=input_model.tickers, matrix=matrix)


async def _fetch_ohlcv_for_tickers_async(
    tickers: Sequence[str],
    *,
    from_date,
    to_date,
    max_lookback_days: int,
):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö."""
    data: dict[str, Sequence] = {}
    for ticker in tickers:
        data[ticker] = await asyncio.to_thread(
            _iss_client.get_ohlcv_series,
            ticker=ticker,
            board=_iss_client.settings.default_board,
            from_date=from_date,
            to_date=to_date,
            interval="1d",
            max_lookback_days=max_lookback_days,
        )
    return data


@mcp.tool(
    name="compute_correlation_matrix",
    description="""üìä –í—ã—á–∏—Å–ª–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–ø–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.

–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
–æ –¥–æ—Ö–æ–¥–∞—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.

–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
- –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é –º–µ–∂–¥—É –∞–∫—Ü–∏—è–º–∏ –±–∞–Ω–∫–æ–≤
- –û—Ü–µ–Ω–∏—Ç—å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ—Ä—Ç—Ñ–µ–ª—è
- –ù–∞–π—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å –Ω–∏–∑–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
""",
)
async def compute_correlation_matrix(
    tickers: List[str] = Field(
        ...,
        description="–°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–º–∏–Ω–∏–º—É–º 2)",
    ),
    from_date: str = Field(
        ...,
        description="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –ø–µ—Ä–∏–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)",
    ),
    to_date: str = Field(
        ...,
        description="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –ø–µ—Ä–∏–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)",
    ),
    ctx: Context = None,
) -> ToolResult:
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–ø–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.

    Args:
        tickers: –°–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π (–º–∏–Ω–∏–º—É–º 2)
        from_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –ø–µ—Ä–∏–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
        to_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –ø–µ—Ä–∏–æ–¥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
        ctx: –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

    Returns:
        ToolResult: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –º–∞—Ç—Ä–∏—Ü–µ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

    Raises:
        McpError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    """
    tool_name = "compute_correlation_matrix"
    start_ts = None

    if _metrics:
        start_ts = time.perf_counter()
        _metrics.inc_tool_call(tool_name)

    if _tracing:
        span_context = _tracing.start_span(tool_name)
    else:
        span_context = tracer.start_as_current_span(tool_name)

    with span_context as span:
        if span is None:
            span = _NOOP_SPAN
        try:
            if ctx:
                await ctx.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å—á—ë—Ç –º–∞—Ç—Ä–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –¥–ª—è {len(tickers)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
                await ctx.report_progress(progress=0, total=100)

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å–ø–∞–Ω–∞
            span.set_attribute("tickers_count", len(tickers))
            span.set_attribute("from_date", from_date)
            span.set_attribute("to_date", to_date)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if ctx:
                await ctx.info("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
                await ctx.report_progress(progress=10, total=100)

            payload = {
                "tickers": tickers,
                "from_date": from_date,
                "to_date": to_date,
            }
            input_model = CorrelationMatrixInput.model_validate(payload)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤
            if len(input_model.tickers) > _max_tickers:
                raise TooManyTickersError(
                    f"Too many tickers: {len(input_model.tickers)} > {_max_tickers}",
                    details={"tickers": input_model.tickers},
                )
            validate_date_range(input_model.from_date, input_model.to_date, max_lookback_days=_max_lookback_days)

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            if ctx:
                await ctx.info("üì° –ó–∞–ø—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
                await ctx.report_progress(progress=20, total=100)

            ohlcv_by_ticker = await _fetch_ohlcv_for_tickers_async(
                input_model.tickers,
                from_date=input_model.from_date,
                to_date=input_model.to_date,
                max_lookback_days=_max_lookback_days,
            )

            if ctx:
                await ctx.info("üìä –†–∞—Å—á—ë—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π")
                await ctx.report_progress(progress=50, total=100)

            returns_by_ticker = await asyncio.to_thread(build_returns_by_ticker, ohlcv_by_ticker)

            if ctx:
                await ctx.info("üìà –†–∞—Å—á—ë—Ç –º–∞—Ç—Ä–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π")
                await ctx.report_progress(progress=70, total=100)

            matrix, calc_metadata = await asyncio.to_thread(
                calc_correlation_matrix, input_model.tickers, returns_by_ticker
            )

            metadata = {
                "from_date": input_model.from_date.isoformat(),
                "to_date": input_model.to_date.isoformat(),
                "tickers": input_model.tickers,
                "method": calc_metadata.get("method"),
                "num_observations": calc_metadata.get("num_observations"),
                "iss_base_url": _iss_client.settings.base_url,
            }

            output = CorrelationMatrixOutput.success(metadata=metadata, tickers=input_model.tickers, matrix=matrix)

            if ctx:
                await ctx.info("‚úÖ –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                await ctx.report_progress(progress=100, total=100)

            span.set_attribute("success", True)
            span.set_attribute("matrix_size", len(matrix))

            return ToolResult.from_dict(output.model_dump(mode="json"))

        except ValueError as e:
            error_type = ErrorMapper.get_error_type_for_exception(e)
            if _metrics:
                _metrics.inc_tool_error(tool_name, error_type)
            span.set_attribute("error", str(e))
            span.set_attribute("error_type", error_type)
            if ctx:
                await ctx.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            error_model = _map_error(e)
            output = CorrelationMatrixOutput.from_error(error_model)
            return ToolResult.from_dict(output.model_dump(mode="json"))

        except Exception as exc:
            error_type = ErrorMapper.get_error_type_for_exception(exc)
            if _metrics:
                _metrics.inc_tool_error(tool_name, error_type)
            span.set_attribute("error", str(exc))
            span.set_attribute("error_type", error_type)

            if ctx:
                await ctx.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {exc}")

            error_model = _map_error(exc)
            metadata = {
                "from_date": from_date,
                "to_date": to_date,
                "tickers": tickers,
            }
            output = CorrelationMatrixOutput.from_error(error_model, metadata=metadata)

            return ToolResult.from_dict(output.model_dump(mode="json"))

        finally:
            if _metrics and start_ts:
                _metrics.observe_latency(tool_name, time.perf_counter() - start_ts)


__all__ = [
    "compute_correlation_matrix_core",
    "compute_correlation_matrix",
]
